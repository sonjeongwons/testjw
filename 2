extensions:
  basicauth/otel:
    client_auth:
      username: 'dbq_data' # PARAM : connection.env value update
      password: '!DBQ_PW123' # PARAM : connection.env value update
  file_storage/logs:
    create_directory: true
    directory: /var/lib/otelcol/file_storage/gateway
    timeout: 1s
    compaction:
      on_rebound: true
      rebound_needed_threshold_mib: 100
      rebound_trigger_threshold_mib: 10
      check_interval: 5s
      cleanup_on_start: true
      directory: /var/lib/otelcol/file_storage/gateway/tmp

processors:
  batch: {}
  memory_limiter:
    check_interval: 1s
    limit_mib: 462
    limit_percentage: 80
    spike_limit_mib: 92
    spike_limit_percentage: 25
  resourcedetection/system:
    detectors: ["system"]
    system:
      hostname_sources: ["os"]
  resource:
    attributes:
      - key: "lma-tenant"
        value: "dbq"  # PARAM :: vmdb1
        action: insert
      - key: "node.ip"
        value: '${env:HOSTNAME}'
        action: insert
  transform:
    metric_statements:
      - context: datapoint
        statements:
          - set(attributes["host.name"], resource.attributes["host.name"])
          - set(attributes["node.ip"], resource.attributes["node.ip"])
          - set(attributes["process.command"], resource.attributes["process.command"])
          - set(attributes["process.command_line"], resource.attributes["process.command_line"])
          - set(attributes["process.executable.name"], resource.attributes["process.executable.name"])
          - set(attributes["process.executable.path"], resource.attributes["process.executable.path"])
          - set(attributes["process.owner"], resource.attributes["process.owner"])
          - set(attributes["process.parent_pid"], resource.attributes["process.parent_pid"])
          - set(attributes["process.pid"], resource.attributes["process.pid"])

receivers:
  otlp:
    protocols:
      grpc:
        endpoint: '127.0.0.1:4317'
      http:
        endpoint: '127.0.0.1:4318'

  # METRIC Reciever START
  hostmetrics:
    collection_interval: 30s
    root_path:
    scrapers:
      cpu:
        metrics:
          system.cpu.logical.count:
            enabled: true
          system.cpu.utilization:
            enabled: true
      memory:
        metrics:
          system.memory.utilization:
            enabled: true
          system.memory.limit:
            enabled: true
      load:
      disk:
      filesystem:
        metrics:
          system.filesystem.utilization:
            enabled: true
      network:
      paging:
      processes:
  prometheus:
    config:
      scrape_configs:
        - job_name: 'otel-collector-${env:HOSTNAME}'  # PARAM :: -db1 
          scrape_interval: 30s # default 5s
          static_configs:
            - targets: ['0.0.0.0:8888']
  # METRIC Reciever END

  # LOG Reciever START
  filelog:
    exclude:
    - /var/log/pods/lma_agent-opentelemetry-collector*_*/opentelemetry-collector/*.log
    include:
    - /var/log/pods/*/*/*.log
    include_file_name: false
    include_file_path: true
    retry_on_failure:
      enabled: true
    start_at: end
  # LOG Reciever END

exporters:
  debug: {}
  # if you need to debug log on pod, use this exporters on piplines
  prometheusremotewrite/otel:
    endpoint: "https://cortex-paas.kr-west1.dev2.samsungsdscloud.com/api/v1/push" # vmware cortex remote write url
    tls:
      insecure: true
    external_labels:
      otel_collector: server
      node_name: '${env:HOSTNAME}'
      node_ip: '${env:HOSTNAME}'
    headers:
      X-Scope-OrgID: 'dbq' # PARAM :: cortex tenant id.
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 24h
    remote_write_queue:
      enabled: true
      queue_size: 10000
    # timeout: 5s
  opensearch/otel:
    # Index Pattern will be : ss4o_{type}-{dataset}-{namespace}
    #dataset: apps
    #namespace: otel
    # If use this, pattern will be {logs_index}
    logs_index: dbq-logs
    http:
      tls:
        insecure_skip_verify: true
      endpoint: https://opensearch-paas.kr-west1.dev2.samsungsdscloud.com
      timeout: 2m
      headers:
        #Content-Type: "application/json"
      auth:
        authenticator: basicauth/otel
    retry_on_failure:
      enabled: true
      initial_interval: 5s
      max_interval: 30s
      max_elapsed_time: 24h
    sending_queue:
      enabled: true
      num_consumers: 10
      queue_size: 100000
      storage: file_storage/logs
    # timeout: 5s
  awss3/otel:
    s3uploader:
      region: 'kr-west1'
      s3_bucket: 'paas-lma-logs'
      s3_prefix: 'dbq'
      s3_partition: 'hour'
      s3_force_path_style: true
      disable_ssl: true
      endpoint: 'https://object-store.private.kr-west1.dev2.samsungsdscloud.com'
    sending_queue:
      enabled: true
      num_consumers: 1
      queue_size: 100000
      storage: file_storage/logs
service:
  extensions:
    - basicauth/otel
    - file_storage/logs
  telemetry:
    metrics:
      address: 0.0.0.0:8888
      level: detailed
  pipelines:
    logs:
      exporters: [opensearch/otel, awss3/otel]
      processors: [resource, transform, memory_limiter, batch]
      receivers: [otlp, filelog]
    metrics:
      exporters: [prometheusremotewrite/otel]
      processors: [resourcedetection/system, resource, transform, memory_limiter, batch]
      receivers: [otlp, hostmetrics, prometheus]
